import requests
from bs4 import BeautifulSoup
import datetime

def get_menu_data(url):
    """ì£¼ì–´ì§„ URLì—ì„œ HTMLì„ ê°€ì ¸ì™€ BeautifulSoup ê°ì²´ë¡œ ë°˜í™˜"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return BeautifulSoup(response.text, "html.parser")
    except requests.exceptions.RequestException as e:
        print(f"ì›¹ì‚¬ì´íŠ¸ ì ‘ì† ì˜¤ë¥˜: {url} - {e}")
        return None

def scrape_weekly_menu(soup, restaurant_name, today_date_str):
    """ì£¼ê°„ ë©”ë‰´ í˜•ì‹ì˜ í˜ì´ì§€ì—ì„œ ì˜¤ëŠ˜ì˜ ë©”ë‰´ë¥¼ ì¶”ì¶œ (êµ¬ì‹œì¬, í–‰ë‹¨ê³¨)"""
    print(f"-> '{restaurant_name}' (ì£¼ê°„ ë©”ë‰´) ìŠ¤í¬ë˜í•‘ ì¤‘...")
    weekly_list_container = soup.find('div', class_='weekly_list')
    if not weekly_list_container:
        return []

    daily_menus = weekly_list_container.find_all('div', class_='weeListWrap')
    
    menus_of_the_day = []
    
    for daily_menu in daily_menus:
        raw_day_title = daily_menu.find('div', class_='weeListTit').get_text()
        day_title = ' '.join(raw_day_title.split())

        # ì˜¤ëŠ˜ ë‚ ì§œì™€ ì¼ì¹˜í•˜ëŠ” ë©”ë‰´ ë¸”ë¡ì„ ì°¾ìŒ
        if today_date_str in day_title:
            # í•œ ë‚ ì§œì— ì—¬ëŸ¬ ì½”ë„ˆê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ëª¨ë‘ ì°¾ìŒ
            menu_contents = daily_menu.find_all('div', class_='weeListCont')
            for content in menu_contents:
                corner = content.find('h6').get_text(strip=True).replace('ì½”ë„ˆ', '').strip()
                menu_items_pre = content.find('pre')
                menu_items = menu_items_pre.get_text('\n', strip=True).strip() if menu_items_pre else "ë©”ë‰´ ì •ë³´ ì—†ìŒ"
                
                price_li = content.select_one('ul > li:nth-of-type(2)')
                price = price_li.get_text(strip=True) if price_li and price_li.get_text(strip=True) else "ê°€ê²© ì •ë³´ ì—†ìŒ"

                menus_of_the_day.append({'corner': corner, 'price': price, 'items': menu_items})
            break # ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ì°¾ì•˜ìœ¼ë©´ ì¢…ë£Œ
            
    return menus_of_the_day

def scrape_daily_menu(soup, restaurant_name):
    """ì¼ì¼ ë©”ë‰´ í˜•ì‹ì˜ í˜ì´ì§€ì—ì„œ ë©”ë‰´ë¥¼ ì¶”ì¶œ (í•´ì˜¤ë¦„)"""
    print(f"-> '{restaurant_name}' (ì¼ì¼ ë©”ë‰´) ìŠ¤í¬ë˜í•‘ ì¤‘...")
    oneday_list_container = soup.find('div', class_='oneday_list')
    if not oneday_list_container:
        return []

    corner_boxes = oneday_list_container.find_all('div', class_='corner_box')
    
    menus_of_the_day = []

    for box in corner_boxes:
        corner = box.find('h5').get_text(strip=True)
        menu_title_pre = box.find('pre')
        menu_items = menu_title_pre.get_text(strip=True) if menu_title_pre else "ë©”ë‰´ ì •ë³´ ì—†ìŒ"
        
        # ê°€ê²© ì •ë³´ê°€ "ê°€ê²© : 5500" í˜•ì‹ìœ¼ë¡œ ë˜ì–´ ìˆì–´ ë¶„ë¦¬ í›„ì²˜ë¦¬
        price_span = box.select_one('li > span')
        price = "ê°€ê²© ì •ë³´ ì—†ìŒ"
        if price_span and 'ê°€ê²©' in price_span.text:
            try:
                price_text = price_span.get_text(strip=True).split(':')[1].strip()
                price = f"{price_text}"
            except IndexError:
                price = "ê°€ê²© ì •ë³´ ì—†ìŒ"
        
        menus_of_the_day.append({'corner': corner, 'price': price, 'items': menu_items})

    return menus_of_the_day

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì˜¤ëŠ˜ ë‚ ì§œë¥¼ "(ì›”.ì¼)" í˜•ì‹ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤. (ì˜ˆ: (07.14))
    today_date_str = datetime.datetime.now().strftime("(%m.%d)")
    
    # ìŠ¤í¬ë˜í•‘í•  ì‹ë‹¹ ëª©ë¡
    restaurants = {
        "êµ¬ì‹œì¬ì‹ë‹¹": {
            "url": "https://www.skku.edu/skku/campus/support/welfare_11_1.do?mode=info&conspaceCd=20201040&srResId=11&srShowTime=W&srCategory=L",
            "type": "weekly"
        },
        "í–‰ë‹¨ê³¨ì‹ë‹¹": {
            "url": "https://www.skku.edu/skku/campus/support/welfare_11_1.do?mode=info&conspaceCd=20201104&srResId=3&srShowTime=W&srCategory=L",
            "type": "weekly"
        },
        "í•´ì˜¤ë¦„ì‹ë‹¹": {
            "url": "https://www.skku.edu/skku/campus/support/welfare_11_1.do?mode=info&conspaceCd=20201251&srResId=12&srShowTime=D&srCategory=L",
            "type": "daily"
        }
    }

    all_today_menus = {}

    for name, info in restaurants.items():
        soup = get_menu_data(info['url'])
        if not soup:
            continue

        if info['type'] == 'weekly':
            menus = scrape_weekly_menu(soup, name, today_date_str)
        elif info['type'] == 'daily':
            menus = scrape_daily_menu(soup, name)
        
        if menus:
            all_today_menus[name] = menus

    # --- ìµœì¢… ê²°ê³¼ ì¶œë ¥ ---
    today_title = datetime.datetime.now().strftime("%Yë…„ %mì›” %dì¼")
    print("\n\n" + "="*40)
    print(f"âœ¨ {today_title} ì˜¤ëŠ˜ì˜ í•™ì‹ ë©”ë‰´ âœ¨")
    print("="*40 + "\n")

    if not all_today_menus:
        print("ğŸ˜¢ ì˜¤ëŠ˜ ì œê³µë˜ëŠ” ì‹ë‹¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    for restaurant, menus in all_today_menus.items():
        print(f"ğŸ± {restaurant}")
        print("-"*20)
        for menu in menus:
            # ê°€ê²©ì´ ìˆ«ìë©´ 'ì›'ì„ ë¶™ì´ê³ , ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ì¶œë ¥
            price_str = f"{menu['price']}ì›" if menu['price'].isdigit() else menu['price']
            print(f"[{menu['corner']}] ({price_str})")
            # ë©”ë‰´ í•­ëª©ì„ í•œ ì¤„ì”© ì¶œë ¥
            for item in menu['items'].split('\n'):
                print(f"  - {item.strip()}")
            print() # ë©”ë‰´ ê°„ ê°„ê²©
        print("\n" + "="*30 + "\n")


if __name__ == "__main__":
    main()
